#!/usr/bin/env python3
"""
æœ¬åœ°æµ‹è¯•è„šæœ¬ - æ¨¡æ‹Ÿ GitHub Actions çš„åˆ†ææµç¨‹
"""
import os
import sys
import json
import subprocess
from datetime import datetime
from pathlib import Path

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
os.chdir(PROJECT_ROOT)

def clone_repo_meta_agent():
    """å…‹éš† RepoMetaAgent é¡¹ç›®"""
    repo_path = PROJECT_ROOT / "RepoMetaAgent--Github-Repo-Analyzer"
    if not repo_path.exists():
        print("ğŸ“¦ æ­£åœ¨å…‹éš† RepoMetaAgent é¡¹ç›®...")
        subprocess.run([
            "git", "clone",
            "https://github.com/shahzaibsalem/RepoMetaAgent--Github-Repo-Analyzer.git"
        ], check=True)
        print("âœ… å…‹éš†å®Œæˆ")
    else:
        print("âœ… RepoMetaAgent å·²å­˜åœ¨")
    return repo_path

def install_dependencies(repo_path):
    """å®‰è£… RepoMetaAgent çš„ä¾èµ–"""
    req_file = repo_path / "requirements.txt"
    if req_file.exists():
        print("ğŸ“¦ æ­£åœ¨å®‰è£… RepoMetaAgent ä¾èµ–...")
        subprocess.run(["pip", "install", "-r", str(req_file)], 
                      capture_output=True)
        print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")

def run_analysis(repo_url: str):
    """è¿è¡Œä»“åº“åˆ†æ"""
    print(f"\nğŸ” å¼€å§‹åˆ†æä»“åº“: {repo_url}")
    
    # æ£€æŸ¥ API å¯†é’¥
    from dotenv import load_dotenv
    load_dotenv()
    
    openai_key = os.getenv("OPENAI_API_KEY", "")
    groq_key = os.getenv("GROQ_API_KEY", "")
    
    if not openai_key and not groq_key:
        print("âš ï¸  æœªé…ç½® API å¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•")
        return generate_mock_results(repo_url)
    
    # å°è¯•è¿è¡ŒçœŸå®åˆ†æ
    try:
        repo_path = clone_repo_meta_agent()
        install_dependencies(repo_path)
        
        sys.path.insert(0, str(repo_path / "code"))
        os.chdir(repo_path / "code")
        
        from __Runner__ import run_assembly_line_analysis
        results = run_assembly_line_analysis(repo_url)
        
        os.chdir(PROJECT_ROOT)
        return results
        
    except Exception as e:
        print(f"âš ï¸  åˆ†æå¤±è´¥: {e}")
        print("ğŸ“ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç»§ç»­æµ‹è¯•...")
        os.chdir(PROJECT_ROOT)
        return generate_mock_results(repo_url)

def generate_mock_results(repo_url: str):
    """ç”Ÿæˆæ¨¡æ‹Ÿåˆ†æç»“æœç”¨äºæµ‹è¯•"""
    repo_name = repo_url.rstrip('/').split('/')[-1]
    
    return {
        "long_summary": f"""è¿™æ˜¯ä¸€ä¸ª GitHub é¡¹ç›®åˆ†æçš„æ¨¡æ‹Ÿç»“æœã€‚

{repo_name} æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼ŒåŒ…å«äº†å®Œæ•´çš„ä»£ç å®ç°å’Œæ–‡æ¡£ã€‚è¯¥é¡¹ç›®é‡‡ç”¨ç°ä»£åŒ–çš„å¼€å‘å®è·µï¼Œå…·æœ‰è‰¯å¥½çš„ä»£ç ç»“æ„å’Œå¯ç»´æŠ¤æ€§ã€‚

ä¸»è¦ç‰¹ç‚¹ï¼š
- æ¸…æ™°çš„é¡¹ç›®ç»“æ„
- å®Œå–„çš„æ–‡æ¡£è¯´æ˜
- æ´»è·ƒçš„ç¤¾åŒºæ”¯æŒ""",
        
        "short_summary": f"{repo_name} æ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œå–„çš„å¼€æºé¡¹ç›®ï¼Œæä¾›äº†ä¾¿æ·çš„å¼€å‘ä½“éªŒã€‚",
        
        "keywords": ["å¼€æº", "GitHub", "é¡¹ç›®åˆ†æ", "è‡ªåŠ¨åŒ–", "Python"],
        
        "github_topics": ["python", "automation", "github", "analysis"],
        
        "file_structure": {
            "README.md": "é¡¹ç›®è¯´æ˜",
            "requirements.txt": "Python ä¾èµ–",
            "src/": "æºä»£ç ç›®å½•",
            "tests/": "æµ‹è¯•ä»£ç "
        },
        
        "review_report": """### ä¼˜ç‚¹

1. **ä»£ç ç»“æ„æ¸…æ™°**ï¼šé¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤
2. **æ–‡æ¡£å®Œå–„**ï¼šREADME è¯¦ç»†è¯´æ˜äº†é¡¹ç›®ç”¨é€”å’Œä½¿ç”¨æ–¹æ³•
3. **æµ‹è¯•è¦†ç›–**ï¼šåŒ…å«å•å…ƒæµ‹è¯•ï¼Œä¿è¯ä»£ç è´¨é‡

### éœ€è¦æ”¹è¿›

1. å¯ä»¥æ·»åŠ æ›´å¤šçš„ä½¿ç”¨ç¤ºä¾‹
2. å»ºè®®å¢åŠ  CI/CD é…ç½®
3. å¯ä»¥è€ƒè™‘æ·»åŠ  Docker æ”¯æŒ""",
        
        "missing_documentation": [
            "API æ–‡æ¡£",
            "è´¡çŒ®æŒ‡å—",
            "æ›´æ–°æ—¥å¿—"
        ],
        
        "suggested_title": f"æ¨èä½¿ç”¨ {repo_name} æ¥æå‡å¼€å‘æ•ˆç‡"
    }

def generate_hugo_markdown(results: dict, repo_url: str):
    """ç”Ÿæˆ Hugo æ ¼å¼çš„ Markdown"""
    # ä¿å­˜åˆ†æç»“æœ
    with open("analysis_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜å…ƒæ•°æ®
    meta = {
        "repo_url": repo_url,
        "analyzed_at": datetime.now().isoformat(),
        "title": "",
        "openai_model": "local-test",
        "openai_api_base": "local"
    }
    with open("analysis_meta.json", "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    
    # è¿è¡Œ Hugo Markdown ç”Ÿæˆè„šæœ¬
    print("\nğŸ“ ç”Ÿæˆ Hugo Markdown...")
    subprocess.run([sys.executable, "scripts/generate_hugo_markdown.py"], check=True)
    
    # è¯»å–ç”Ÿæˆçš„æ–‡ä»¶
    with open("analysis.md", "r", encoding="utf-8") as f:
        markdown = f.read()
    
    with open("filename.txt", "r", encoding="utf-8") as f:
        filename = f.read().strip()
    
    return markdown, filename

def main():
    print("=" * 60)
    print("ğŸ¤– GitHub é¡¹ç›®åˆ†æå™¨ - æœ¬åœ°æµ‹è¯•")
    print("=" * 60)
    
    # è·å–è¦åˆ†æçš„ä»“åº“ URL
    if len(sys.argv) > 1:
        repo_url = sys.argv[1]
    else:
        repo_url = input("\nè¯·è¾“å…¥è¦åˆ†æçš„ GitHub ä»“åº“é“¾æ¥: ").strip()
    
    if not repo_url:
        repo_url = "https://github.com/microsoft/vscode"
        print(f"ä½¿ç”¨é»˜è®¤ä»“åº“: {repo_url}")
    
    if not repo_url.startswith("https://github.com/"):
        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ GitHub ä»“åº“é“¾æ¥")
        return
    
    # è¿è¡Œåˆ†æ
    results = run_analysis(repo_url)
    
    # ç”Ÿæˆ Hugo Markdown
    markdown, filename = generate_hugo_markdown(results, repo_url)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print(f"âœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶: {filename}")
    print("=" * 60)
    
    print("\nğŸ“‹ Markdown é¢„è§ˆ (å‰ 50 è¡Œ):")
    print("-" * 40)
    lines = markdown.split('\n')[:50]
    print('\n'.join(lines))
    print("-" * 40)
    print(f"... (å…± {len(markdown.split(chr(10)))} è¡Œ)")
    
    print(f"\nğŸ“ å®Œæ•´æ–‡ä»¶å·²ä¿å­˜åˆ°: {PROJECT_ROOT / 'analysis.md'}")

if __name__ == "__main__":
    main()
