#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„ GitHub ä»“åº“åˆ†æè„šæœ¬
ä¸ä¾èµ– RepoMetaAgentï¼Œç›´æ¥ä½¿ç”¨ GitHub API å’Œ OpenAI API
"""
import os
import sys
import json
import requests
from datetime import datetime

# GitHub API é…ç½®
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN", "")
GITHUB_HEADERS = {
    "Accept": "application/vnd.github.v3+json",
}
if GITHUB_TOKEN:
    GITHUB_HEADERS["Authorization"] = f"token {GITHUB_TOKEN}"

# OpenAI API é…ç½®
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
OPENAI_API_BASE = os.environ.get("OPENAI_API_BASE", "https://api.openai.com/v1")
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4-turbo-preview")


def parse_repo_url(url: str) -> tuple:
    """è§£æ GitHub ä»“åº“ URL"""
    url = url.rstrip("/").replace(".git", "")
    parts = url.split("/")
    owner = parts[-2]
    repo = parts[-1]
    return owner, repo


def fetch_repo_info(owner: str, repo: str) -> dict:
    """è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯"""
    url = f"https://api.github.com/repos/{owner}/{repo}"
    response = requests.get(url, headers=GITHUB_HEADERS)
    response.raise_for_status()
    return response.json()


def fetch_readme(owner: str, repo: str) -> str:
    """è·å– README å†…å®¹"""
    url = f"https://api.github.com/repos/{owner}/{repo}/readme"
    response = requests.get(url, headers=GITHUB_HEADERS)
    if response.status_code == 200:
        import base64
        content = response.json().get("content", "")
        try:
            return base64.b64decode(content).decode("utf-8")
        except:
            return ""
    return ""


def fetch_file_tree(owner: str, repo: str, max_depth: int = 3) -> dict:
    """è·å–æ–‡ä»¶æ ‘ç»“æ„ï¼ˆé™åˆ¶æ·±åº¦é¿å…é€Ÿç‡é™åˆ¶ï¼‰"""
    url = f"https://api.github.com/repos/{owner}/{repo}/git/trees/HEAD?recursive=1"
    response = requests.get(url, headers=GITHUB_HEADERS)
    if response.status_code != 200:
        return {}
    
    data = response.json()
    tree = {}
    
    for item in data.get("tree", [])[:100]:  # é™åˆ¶æ–‡ä»¶æ•°é‡
        path = item["path"]
        parts = path.split("/")
        if len(parts) <= max_depth:
            tree[path] = item["type"]
    
    return tree


def fetch_languages(owner: str, repo: str) -> dict:
    """è·å–ä»“åº“è¯­è¨€ç»Ÿè®¡"""
    url = f"https://api.github.com/repos/{owner}/{repo}/languages"
    response = requests.get(url, headers=GITHUB_HEADERS)
    if response.status_code == 200:
        return response.json()
    return {}


def call_openai(prompt: str, system_prompt: str = "", max_tokens: int = 4000) -> str:
    """è°ƒç”¨ OpenAI API"""
    if not OPENAI_API_KEY:
        return "æœªé…ç½® OpenAI API Key"
    
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})
    
    data = {
        "model": OPENAI_MODEL,
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": max_tokens
    }
    
    try:
        response = requests.post(
            f"{OPENAI_API_BASE}/chat/completions",
            headers=headers,
            json=data,
            timeout=120
        )
        response.raise_for_status()
        result = response.json()
        return result["choices"][0]["message"]["content"]
    except Exception as e:
        print(f"OpenAI API è°ƒç”¨å¤±è´¥: {e}")
        return f"AI åˆ†æå¤±è´¥: {str(e)}"


def analyze_repository(repo_url: str) -> dict:
    """åˆ†æ GitHub ä»“åº“"""
    print(f"ğŸ“Š å¼€å§‹åˆ†æä»“åº“: {repo_url}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {OPENAI_MODEL}")
    print(f"ğŸ”— API ç«¯ç‚¹: {OPENAI_API_BASE}")
    
    owner, repo = parse_repo_url(repo_url)
    print(f"ğŸ“ ä»“åº“: {owner}/{repo}")
    
    # è·å–ä»“åº“ä¿¡æ¯
    print("ğŸ“¥ è·å–ä»“åº“ä¿¡æ¯...")
    try:
        repo_info = fetch_repo_info(owner, repo)
    except Exception as e:
        print(f"âŒ è·å–ä»“åº“ä¿¡æ¯å¤±è´¥: {e}")
        return generate_fallback_results(repo_url, owner, repo, str(e))
    
    # è·å– README
    print("ğŸ“„ è·å– README...")
    readme = fetch_readme(owner, repo)
    
    # è·å–æ–‡ä»¶ç»“æ„
    print("ğŸ“‚ è·å–æ–‡ä»¶ç»“æ„...")
    file_tree = fetch_file_tree(owner, repo)
    
    # è·å–è¯­è¨€ç»Ÿè®¡
    print("ğŸ’» è·å–è¯­è¨€ç»Ÿè®¡...")
    languages = fetch_languages(owner, repo)
    
    # å‡†å¤‡åˆ†æä¸Šä¸‹æ–‡
    context = f"""
ä»“åº“åç§°: {repo_info.get('name', repo)}
æè¿°: {repo_info.get('description', 'æ— æè¿°')}
ä¸»è¦è¯­è¨€: {repo_info.get('language', 'æœªçŸ¥')}
Star æ•°: {repo_info.get('stargazers_count', 0)}
Fork æ•°: {repo_info.get('forks_count', 0)}
ä¸»é¢˜æ ‡ç­¾: {', '.join(repo_info.get('topics', []))}
è®¸å¯è¯: {repo_info.get('license', {}).get('name', 'æœªçŸ¥') if repo_info.get('license') else 'æœªçŸ¥'}

è¯­è¨€ç»Ÿè®¡: {json.dumps(languages, ensure_ascii=False)}

æ–‡ä»¶ç»“æ„ (éƒ¨åˆ†):
{json.dumps(list(file_tree.keys())[:50], ensure_ascii=False, indent=2)}

README å†…å®¹ (å‰ 3000 å­—ç¬¦):
{readme[:3000] if readme else 'æ—  README'}
"""
    
    # AI åˆ†æ
    print("ğŸ§  AI åˆ†æä¸­...")
    
    system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¼€æºé¡¹ç›®æ¨èä¸“å®¶ï¼Œæ­£åœ¨ä¸ºæŠ€æœ¯å‘¨åˆŠæ’°å†™é¡¹ç›®æ¨èæ–‡ç« ã€‚
ä½ çš„æ–‡ç« é£æ ¼ï¼š
- çƒ­æƒ…æ´‹æº¢ä½†ä¸å¤±ä¸“ä¸š
- æ·±å…¥æµ…å‡ºï¼Œè®©è¯»è€…å¿«é€Ÿç†è§£é¡¹ç›®ä»·å€¼
- ç»“åˆå®é™…ä½¿ç”¨åœºæ™¯ï¼Œç»™å‡ºå…·ä½“çš„æ¨èç†ç”±
- å†…å®¹è¯¦å®ä¸°å¯Œï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½è¦æœ‰è¶³å¤Ÿçš„ä¿¡æ¯é‡
è¯·ç”¨ä¸­æ–‡æ’°å†™ï¼Œè¯­è¨€ç”ŸåŠ¨æœ‰è¶£ã€‚"""
    
    analysis_prompt = f"""è¯·ä¸ºä»¥ä¸‹ GitHub é¡¹ç›®æ’°å†™ä¸€ç¯‡è¯¦ç»†çš„å‘¨åˆŠæ¨èæ–‡ç« ï¼š

{context}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼æ’°å†™ï¼ˆæ¯ä¸ªéƒ¨åˆ†ç”¨ ### æ ‡é¢˜åˆ†éš”ï¼Œå†…å®¹è¦è¯¦ç»†ä¸°å¯Œï¼‰ï¼š

### é¡¹ç›®äº®ç‚¹
ï¼ˆç”¨ 3-5 å¥è¯æ¦‚æ‹¬è¿™ä¸ªé¡¹ç›®æœ€å¸å¼•äººçš„åœ°æ–¹ï¼Œä¸ºä»€ä¹ˆå€¼å¾—æ¨èï¼Œè¦æœ‰æ„ŸæŸ“åŠ›ï¼‰

### é¡¹ç›®ç®€ä»‹
ï¼ˆ400-600å­—çš„è¯¦ç»†ä»‹ç»ï¼ŒåŒ…æ‹¬é¡¹ç›®èƒŒæ™¯ã€è§£å†³çš„é—®é¢˜ã€æ ¸å¿ƒç†å¿µç­‰ï¼‰

### æ ¸å¿ƒåŠŸèƒ½
ï¼ˆè¯¦ç»†ä»‹ç» 5-8 ä¸ªä¸»è¦åŠŸèƒ½ï¼Œæ¯ä¸ªåŠŸèƒ½ç”¨ **åŠŸèƒ½å**ï¼šæè¿° çš„æ ¼å¼ï¼Œæè¿°è¦å…·ä½“ï¼‰

### æŠ€æœ¯æ¶æ„
ï¼ˆè¯¦ç»†åˆ†ææŠ€æœ¯æ ˆé€‰å‹ã€æ¶æ„è®¾è®¡ã€ä»£ç ç»„ç»‡ç­‰ï¼Œ300-400å­—ï¼‰

### å¿«é€Ÿä¸Šæ‰‹
ï¼ˆæä¾›è¯¦ç»†çš„å®‰è£…å’Œä½¿ç”¨æ­¥éª¤ï¼ŒåŒ…æ‹¬å‘½ä»¤ç¤ºä¾‹ï¼‰

### ä½¿ç”¨åœºæ™¯
ï¼ˆåˆ—å‡º 3-5 ä¸ªå…·ä½“çš„ä½¿ç”¨åœºæ™¯ï¼Œè¯´æ˜ä»€ä¹ˆæ ·çš„äºº/å›¢é˜Ÿé€‚åˆä½¿ç”¨ï¼‰

### ä¼˜åŠ¿åˆ†æ
ï¼ˆè¯¦ç»†åˆ†æ 5 ä¸ªä»¥ä¸Šçš„ä¼˜ç‚¹ï¼Œæ¯ä¸ªä¼˜ç‚¹è¦æœ‰å…·ä½“è¯´æ˜ï¼‰

### å¾…æ”¹è¿›
ï¼ˆå®¢è§‚æŒ‡å‡º 2-3 ä¸ªå¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼‰

### åŒç±»å¯¹æ¯”
ï¼ˆå¦‚æœæœ‰ç±»ä¼¼é¡¹ç›®ï¼Œç®€è¦å¯¹æ¯”ä¼˜åŠ£ï¼‰

### æ¨èç†ç”±
ï¼ˆæ€»ç»“ä¸ºä»€ä¹ˆæ¨èè¿™ä¸ªé¡¹ç›®ï¼Œé€‚åˆä»€ä¹ˆè¯»è€…ï¼Œ100-150å­—ï¼‰
"""
    
    ai_response = call_openai(analysis_prompt, system_prompt)
    
    # è§£æ AI å“åº”
    sections = parse_ai_response(ai_response)
    
    # æå–å…³é”®è¯
    topics = repo_info.get('topics', [])
    if not topics:
        topics = list(languages.keys())[:5] if languages else []
    
    # æ„å»ºç»“æœ
    results = {
        "highlight": sections.get("é¡¹ç›®äº®ç‚¹", ""),
        "long_summary": sections.get("é¡¹ç›®ç®€ä»‹", repo_info.get('description', 'æš‚æ— æè¿°')),
        "core_features": sections.get("æ ¸å¿ƒåŠŸèƒ½", ""),
        "tech_architecture": sections.get("æŠ€æœ¯æ¶æ„", ""),
        "quick_start": sections.get("å¿«é€Ÿä¸Šæ‰‹", ""),
        "use_cases": sections.get("ä½¿ç”¨åœºæ™¯", ""),
        "advantages": sections.get("ä¼˜åŠ¿åˆ†æ", ""),
        "improvements": sections.get("å¾…æ”¹è¿›", ""),
        "comparison": sections.get("åŒç±»å¯¹æ¯”", ""),
        "recommendation": sections.get("æ¨èç†ç”±", ""),
        "short_summary": sections.get("é¡¹ç›®äº®ç‚¹", repo_info.get('description', '')),
        "review_report": f"## ä¼˜åŠ¿åˆ†æ\n\n{sections.get('ä¼˜åŠ¿åˆ†æ', '')}\n\n## å¾…æ”¹è¿›\n\n{sections.get('å¾…æ”¹è¿›', '')}",
        "keywords": topics + list(languages.keys())[:5],
        "github_topics": topics if topics else list(languages.keys())[:5],
        "file_structure": file_tree,
        "missing_documentation": extract_missing_docs(sections.get("å¾…æ”¹è¿›", "")),
        "suggested_title": f"æœ¬å‘¨æ¨èï¼š{repo} - {repo_info.get('description', 'å€¼å¾—å…³æ³¨çš„å¼€æºé¡¹ç›®')[:50]}",
        "tech_analysis": sections.get("æŠ€æœ¯æ¶æ„", ""),
        "repo_info": {
            "name": repo_info.get('name'),
            "full_name": repo_info.get('full_name'),
            "description": repo_info.get('description'),
            "stars": repo_info.get('stargazers_count'),
            "forks": repo_info.get('forks_count'),
            "language": repo_info.get('language'),
            "topics": topics,
            "license": repo_info.get('license', {}).get('name') if repo_info.get('license') else None,
            "html_url": f"https://github.com/{owner}/{repo}",
            "created_at": repo_info.get('created_at'),
            "updated_at": repo_info.get('updated_at'),
            "open_issues": repo_info.get('open_issues_count'),
            "watchers": repo_info.get('watchers_count')
        }
    }
    
    print("âœ… åˆ†æå®Œæˆï¼")
    return results


def parse_ai_response(response: str) -> dict:
    """è§£æ AI å“åº”ä¸ºå„ä¸ªéƒ¨åˆ†"""
    sections = {}
    current_section = None
    current_content = []
    
    for line in response.split('\n'):
        if line.startswith('### '):
            if current_section:
                sections[current_section] = '\n'.join(current_content).strip()
            current_section = line[4:].strip()
            current_content = []
        elif current_section:
            current_content.append(line)
    
    if current_section:
        sections[current_section] = '\n'.join(current_content).strip()
    
    return sections


def extract_missing_docs(text: str) -> list:
    """ä»æ”¹è¿›å»ºè®®ä¸­æå–ç¼ºå¤±æ–‡æ¡£"""
    docs = []
    keywords = ['æ–‡æ¡£', 'è¯´æ˜', 'README', 'API', 'ç¤ºä¾‹', 'æ•™ç¨‹', 'æ³¨é‡Š']
    for keyword in keywords:
        if keyword.lower() in text.lower():
            docs.append(f"å®Œå–„{keyword}")
    return docs if docs else ["æš‚æ— æ˜æ˜¾ç¼ºå¤±"]


def generate_fallback_results(repo_url: str, owner: str, repo: str, error: str) -> dict:
    """ç”Ÿæˆå¤‡ç”¨ç»“æœï¼ˆå½“è·å–ä»“åº“ä¿¡æ¯å¤±è´¥æ—¶ï¼‰"""
    return {
        "long_summary": f"æ— æ³•è·å–ä»“åº“ {owner}/{repo} çš„è¯¦ç»†ä¿¡æ¯ã€‚é”™è¯¯: {error}",
        "short_summary": f"{repo} æ˜¯ä¸€ä¸ª GitHub é¡¹ç›®",
        "review_report": "ç”±äº API é™åˆ¶ï¼Œæ— æ³•å®Œæˆå®Œæ•´åˆ†æ",
        "keywords": [repo, owner, "github"],
        "github_topics": [],
        "file_structure": {},
        "missing_documentation": ["éœ€è¦æ‰‹åŠ¨æŸ¥çœ‹é¡¹ç›®"],
        "suggested_title": f"æ¢ç´¢ {repo} é¡¹ç›®"
    }


def main():
    repo_url = os.environ.get("REPO_URL", "")
    if not repo_url:
        print("é”™è¯¯: æœªæä¾› REPO_URL")
        sys.exit(1)
    
    # è¿è¡Œåˆ†æ
    results = analyze_repository(repo_url)
    
    # ä¿å­˜ç»“æœ
    with open("/tmp/analysis_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜å…ƒæ•°æ®
    meta = {
        "repo_url": repo_url,
        "analyzed_at": datetime.now().isoformat(),
        "title": os.environ.get("ARTICLE_TITLE", ""),
        "openai_model": OPENAI_MODEL,
        "openai_api_base": OPENAI_API_BASE
    }
    with open("/tmp/analysis_meta.json", "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ° /tmp/analysis_results.json")


if __name__ == "__main__":
    main()
