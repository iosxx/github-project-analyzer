name: Analyze GitHub Repo and Publish

on:
  workflow_dispatch:
    inputs:
      repo_url:
        description: 'GitHub Repository URL to analyze'
        required: true
        type: string
        default: 'https://github.com/shahzaibsalem/RepoMetaAgent--Github-Repo-Analyzer'
      title:
        description: 'Article title (optional)'
        required: false
        type: string
        default: ''
      openai_model:
        description: 'OpenAI Model (or custom model for third-party APIs)'
        required: false
        type: string
        default: 'gpt-4-turbo-preview'
      openai_api_base:
        description: 'OpenAI API Base URL (use https://api.agentify.top/v1 for agentify)'
        required: false
        type: string
        default: 'https://api.openai.com/v1'
      hugo_deploy_repo:
        description: 'Target Hugo repo (owner/repo)'
        required: false
        type: string
        default: 'iosxx/notion-hugo-deploy'
      content_path:
        description: 'Content path in Hugo repo'
        required: false
        type: string
        default: 'content/å‘¨åˆŠ'
      publish:
        description: 'Publish to Hugo repo'
        required: false
        type: boolean
        default: true

env:
  PYTHON_VERSION: '3.10'
  ARTICLE_TITLE: ${{ github.event.inputs.title }}
  OPENAI_MODEL: ${{ github.event.inputs.openai_model }}
  OPENAI_API_BASE: ${{ github.event.inputs.openai_api_base }}

jobs:
  analyze-and-publish:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout current repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install streamlit langgraph langsmith langchain-core langchain-openai langchain-groq openai groq gitpython chromadb spacy python-dotenv PyYAML beautifulsoup4 requests pandas numpy

      - name: Clone RepoMetaAgent
        run: |
          git clone https://github.com/shahzaibsalem/RepoMetaAgent--Github-Repo-Analyzer.git
          ls -la RepoMetaAgent--Github-Repo-Analyzer/

      - name: Install additional dependencies for RepoMetaAgent
        run: |
          pip install -r RepoMetaAgent--Github-Repo-Analyzer/requirements.txt || true

      - name: Run Analysis
        id: analyze
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO_URL: ${{ github.event.inputs.repo_url }}
          ARTICLE_TITLE: ${{ env.ARTICLE_TITLE }}
        run: |
          cd RepoMetaAgent--Github-Repo-Analyzer/code
          
          # Create analysis script
          cat > analyze_repo.py << 'EOF'
          import sys
          import os
          import json
          from datetime import datetime
          
          sys.path.append('.')
          
          try:
              from __Runner__ import run_assembly_line_analysis
              
              # Set custom OpenAI configuration
              os.environ['OPENAI_API_BASE'] = '${{ env.OPENAI_API_BASE }}'
              os.environ['OPENAI_MODEL'] = '${{ env.OPENAI_MODEL }}'
              
              repo_url = os.environ.get('REPO_URL')
              if not repo_url:
                  print("Error: REPO_URL not provided")
                  sys.exit(1)
              
              print(f"Analyzing repository: {repo_url}")
              print(f"Using OpenAI model: ${{ env.OPENAI_MODEL }}")
              print(f"Using API base: ${{ env.OPENAI_API_BASE }}")
              
              results = run_assembly_line_analysis(repo_url)
              
              # Save results to JSON file
              with open('/tmp/analysis_results.json', 'w', encoding='utf-8') as f:
                  json.dump(results, f, ensure_ascii=False, indent=2)
              
              # Save repo URL and current date
              analysis_meta = {
                  'repo_url': repo_url,
                  'analyzed_at': datetime.now().isoformat(),
                  'title': os.environ.get('ARTICLE_TITLE', ''),
                  'openai_model': '${{ env.OPENAI_MODEL }}',
                  'openai_api_base': '${{ env.OPENAI_API_BASE }}'
              }
              
              with open('/tmp/analysis_meta.json', 'w', encoding='utf-8') as f:
                  json.dump(analysis_meta, f, ensure_ascii=False, indent=2)
              
              print("Analysis completed successfully")
              print(f"Results saved to /tmp/analysis_results.json")
              
          except Exception as e:
              print(f"Error during analysis: {str(e)}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          EOF
          
          python analyze_repo.py
          
          # Copy results back to workspace
          cp /tmp/analysis_results.json ${{ github.workspace }}/
          cp /tmp/analysis_meta.json ${{ github.workspace }}/
          
          echo "Analysis completed. Results copied to workspace."

      - name: Generate Markdown
        id: generate-markdown
        run: |
          # Use the external Python script to generate Hugo markdown
          python ${{ github.workspace }}/scripts/generate_hugo_markdown.py
          
          # Display the generated markdown
          echo "--- Generated Markdown Preview ---"
          head -80 analysis.md
          echo "..."
          echo "--- End of Preview ---"
          
          # Set output for next step
          echo "filename=$(cat filename.txt)" >> $GITHUB_ENV

      - name: Checkout target Hugo repository
        if: github.event.inputs.publish == 'true'
        uses: actions/checkout@v4
        with:
          repository: ${{ github.event.inputs.hugo_deploy_repo }}
          token: ${{ secrets.PAT_TOKEN || secrets.GITHUB_TOKEN }}
          path: target-repo

      - name: Copy markdown to Hugo content directory
        if: github.event.inputs.publish == 'true'
        run: |
          # Create directory in target repo if it doesn't exist
          mkdir -p "target-repo/${{ github.event.inputs.content_path }}"
          
          # Copy the markdown file
          cp analysis.md "target-repo/${{ github.event.inputs.content_path }}/${{ env.filename }}"
          
          # Show the file tree
          echo "File tree after copy:"
          find "target-repo/${{ github.event.inputs.content_path }}" -name "*.md" | sort

      - name: Commit and Push
        if: github.event.inputs.publish == 'true'
        working-directory: target-repo
        run: |
          # Configure git
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Check if file was added
          git add "${{ github.event.inputs.content_path }}/${{ env.filename }}"
          
          # Get repo info for commit message
          REPO_NAME=$(basename "${{ github.event.inputs.repo_url }}" .git)
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            # Commit with multiline message
            git commit -m "ðŸ“Š Add project analysis: ${REPO_NAME}" \
              -m "Analyzed repository: ${{ github.event.inputs.repo_url }}" \
              -m "Analysis completed at: $(date -u +'%Y-%m-%d %H:%M:%S UTC')" \
              -m "Model: ${{ env.OPENAI_MODEL }}" \
              -m "API: ${{ env.OPENAI_API_BASE }}" \
              -m "ðŸ¤– Generated by GitHub Project Analyzer"
            
            # Push
            git push origin main || git push origin master
          fi

      - name: Upload analysis results as artifact
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: |
            analysis_results.json
            analysis.md
            analysis_meta.json

      - name: Summary
        run: |
          echo "## ðŸ“Š åˆ†æžæ€»ç»“" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**åˆ†æžçš„ä»“åº“**ï¼š${{ github.event.inputs.repo_url }}" >> $GITHUB_STEP_SUMMARY
          echo "**ä½¿ç”¨çš„æ¨¡åž‹**ï¼š${{ env.OPENAI_MODEL }}" >> $GITHUB_STEP_SUMMARY
          echo "**API ç«¯ç‚¹**ï¼š${{ env.OPENAI_API_BASE }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**ç”Ÿæˆçš„æ–‡ä»¶**ï¼š${{ env.filename }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ github.event.inputs.publish }}" == "true" ]; then
            echo "**å‘å¸ƒåˆ°**ï¼š${{ github.event.inputs.hugo_deploy_repo }}/${{ github.event.inputs.content_path }}" >> $GITHUB_STEP_SUMMARY
          else
            echo "**å‘å¸ƒçŠ¶æ€**ï¼šå·²ç¦ç”¨ï¼ˆä»…åˆ†æžï¼Œä¸å‘å¸ƒï¼‰" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“¥ ä¸‹è½½" >> $GITHUB_STEP_SUMMARY
          echo "æ£€æŸ¥ artifacts ä¸‹è½½åˆ†æžç»“æžœï¼š" >> $GITHUB_STEP_SUMMARY
          echo "- åˆ†æžç»“æžœ JSON" >> $GITHUB_STEP_SUMMARY
          echo "- ç”Ÿæˆçš„ Markdown" >> $GITHUB_STEP_SUMMARY
          echo "- å…ƒæ•°æ®ä¿¡æ¯" >> $GITHUB_STEP_SUMMARY
